{
    "collab_server" : "",
    "contents" : "#'\n#'\n#' Regularized Structural Equation Modeling\n#'\n#' @param model Lavaan output object. This is a model that was previously\n#'        run with any of the lavaan main functions: cfa(), lavaan(), sem(),\n#'        or growth(). It also can be from the efaUnrotate() function from\n#'        the semTools package. Currently, the parts of the model which cannot\n#'        be handled in regsem is the use of multiple group models, missing\n#'        other than listwise, thresholds from categorical variable models,\n#'        the use of additional estimators other than\n#'        ML, most notably WLSMV for categorical variables. Note: the model\n#'        does not have to actually run (use do.fit=FALSE), converge etc...\n#'        regsem() uses the lavaan object as more of a parser and to get\n#'        sample covariance matrix.\n#' @param lambda Penalty value. Note: higher values will result in additional\n#'        convergence issues. If using values > 0.1, it is recommended to use\n#'        mutli_optim() instead. See \\code{\\link{multi_optim}} for more detail.\n#' @param alpha Mixture for elastic net. Not currently working applied.\n#' @param gamma Additional penalty for MCP and SCAD\n#' @param type Penalty type. Options include \"none\", \"lasso\", \"ridge\",\n#'        \"enet\" for the elastic net,\n#'        \"alasso\" for the adaptive lasso\n#'        and \"diff_lasso\". diff_lasso penalizes the discrepency between\n#'        parameter estimates and some pre-specified values. The values\n#'        to take the deviation from are specified in diff_par. Two methods for\n#'        sparser results than lasso are the smooth clipped absolute deviation,\n#'        \"scad\", and the minimum concave penalty, \"mcp\".\n#' @param data Optional dataframe. Only required for missing=\"fiml\" which\n#'        is not currently working.\n#' @param optMethod Solver to use. Recommended options include \"nlminb\" and\n#'        \"optimx\". Note: for \"optimx\", the default method is to use nlminb.\n#'        This can be changed in subOpt.\n#' @param gradFun Gradient function to use. Recommended to use \"ram\",\n#'        which refers to the method specified in von Oertzen & Brick (2014).\n#'        The \"norm\" procedure uses the forward difference method for\n#'        calculating the hessian. This is slower and less accurate.\n#' @param hessFun Hessian function to use. Recommended to use \"ram\",\n#'        which refers to the method specified in von Oertzen & Brick (2014).\n#'        The \"norm\" procedure uses the forward difference method for\n#'        calculating the hessian. This is slower and less accurate.\n#' @param parallel Logical. Whether to parallelize the processes?\n#' @param Start type of starting values to use. Only recommended to use\n#'        \"default\". This sets factor loadings and variances to 0.5.\n#'        Start = \"lavaan\" uses the parameter estimates from the lavaan\n#'        model object. This is not recommended as it can increase the\n#'        chances in getting stuck at the previous parameter estimates.\n#' @param subOpt Type of optimization to use in the optimx package.\n#' @param longMod If TRUE, the model is using longitudinal data? This changes\n#'        the sample covariance used.\n#' @param pars_pen Parameter indicators to penalize. If left NULL, by default,\n#'        all parameters in the \\emph{A} matrix outside of the intercepts are\n#'        penalized when lambda > 0 and type != \"none\".\n#' @param diff_par Parameter values to deviate from. Only used when\n#'        type=\"diff_lasso\".\n#' @param LB lower bound vector. Note: This is very important to specify\n#'        when using regularization. It greatly increases the chances of\n#'        converging.\n#' @param UB Upper bound vector\n#' @param par.lim Vector of minimum and maximum parameter estimates. Used to\n#'        stop optimization and move to new starting values if violated.\n#' @param block Whether to use block coordinate descent\n#' @param full Whether to do full gradient descent or block\n#' @param calc Type of calc function to use with means or not. Not recommended\n#'        for use.\n#' @param nlminb.control list of control values to pass to nlminb\n#' @param max.iter Number of iterations for coordinate descent\n#' @param tol Tolerance for coordinate descent\n#' @param solver Whether to use solver for coord_desc\n#' @param solver.maxit Max iterations for solver in coord_desc\n#' @param alpha.inc Whether alpha should increase for coord_desc\n#' @param step Step size\n#' @param momentum Momentum for step sizes\n#' @param step.ratio Ratio of step size between A and S. Logical\n#' @param missing How to handle missing data. Current options are \"listwise\"\n#'        and \"fiml\". \"fiml\" is not currently working well.\n#' @return out List of return values from optimization program\n#' @return convergence Convergence status. 0 = converged, 1 or 99 means the model did not converge.\n#' @return par.ret Final parameter estimates\n#' @return Imp_Cov Final implied covariance matrix\n#' @return grad Final gradient.\n#' @return KKT1 Were final gradient values close enough to 0.\n#' @return KKT2 Was the final Hessian positive definite.\n#' @return df Final degrees of freedom. Note that df changes with lasso\n#'         penalties.\n#' @return npar Final number of free parameters. Note that this can change\n#'         with lasso penalties.\n#' @return SampCov Sample covariance matrix.\n#' @return fit Final F_ml fit. Note this is the final parameter estimates\n#'         evaluated with the F_ml fit function.\n#' @return coefficients Final parameter estimates\n#' @return nvar Number of variables.\n#' @return N sample size.\n#' @return nfac Number of factors\n#' @return baseline.chisq Baseline chi-square.\n#' @return baseline.df Baseline degrees of freedom.\n#' @keywords optim calc\n#' @useDynLib regsem\n#' @import Rcpp\n#' @import lavaan\n#' @importFrom stats cov na.omit nlminb pchisq rnorm runif sd uniroot var weighted.mean\n#' @importFrom graphics abline lines plot\n#' @export\n#' @examples\n#' library(lavaan)\n#' HS <- data.frame(scale(HolzingerSwineford1939[,7:15]))\n#' mod <- '\n#' f =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9\n#' '\n#' # Recommended to specify meanstructure in lavaan\n#' outt = cfa(mod,HS,meanstructure=TRUE)\n#'\n#' fit1 <- regsem(outt,lambda=0.05,type=\"lasso\",pars_pen=c(1:2,6:8))\n#' #summary(fit1)\n\n\n\n\n\nregsem = function(model,lambda=0,alpha=0,gamma=3.7, type=\"none\",data=NULL,optMethod=\"default\",\n                 gradFun=\"ram\",hessFun=\"none\",parallel=\"no\",Start=\"lavaan\",\n                 subOpt=\"nlminb\",longMod=F,\n                 pars_pen=NULL,\n                 diff_par=NULL,\n                 LB=-Inf,\n                 UB=Inf,\n                 par.lim=c(-Inf,Inf),\n                 block=TRUE,\n                 full=TRUE,\n                 calc=\"normal\",\n                 max.iter=500,\n                 tol=1e-5,\n                 solver=FALSE,\n                 solver.maxit=5,\n                 alpha.inc=FALSE,\n                 step=.5,\n                 momentum=FALSE,\n                 step.ratio=FALSE,\n                 nlminb.control=list(),\n                 missing=\"listwise\"){\n\n  e_alpha=alpha\n\n\n  if(type == \"scad\" | type == \"mcp\"){\n    warning(\"this type is currently not working well\")\n  }\n  if(optMethod==\"default\" & type==\"lasso\" | type==\"diff_lasso\" |\n     type==\"enet\" | type==\"alasso\" | type==\"scad\" | type==\"mcp\"){\n      optMethod<-\"coord_desc\"\n  }\n\n  if(optMethod==\"default\" & type==\"ridge\" | type==\"none\"){\n    optMethod <- \"nlminb\"\n  }\n\n\n  if(optMethod!=\"nlminb\" & optMethod !=\"coord_desc\"){\n    stop(\"only optmethod==nlminb or coord_desc is currently supported well\")\n  }\n\n#  if(optMethod==\"nlminb\"& type !=\"ridge\" | type != \"none\"){\n#    stop(\"Only optMethod=coord_desc is recommended for use\")\n#  }\n\n  if(length(nlminb.control)==0){\n    nlminb.control <- list(abs.tol=1e-6,\n                    iter.max=60000,\n                    eval.max=60000,\n                    rel.tol=1e-6,\n                    x.tol=1e-6,\n                    xf.tol=1e-6)\n  }\n\n\n  if(missing==\"fiml\" & is.null(model@SampleStats@missing[[1]])){\n    stop(\"need to change missing=fiml in lavaan\")\n  }\n\n#  if(gradFun != \"none\" & missing==\"fiml\"){\n#    stop(\"only gradFun = none is supported with missing data\")\n#  }\n\n#  if(model@Data@nobs[[1]] != model@Data@norig[[1]]){\n#    warning(\"regsem is currently not working well in the presence of missing data\")\n#  }\n\n\n  #  if(gradFun==\"norm\"){\n  #    stop(\"Only recommended grad function is ram or none at this time\")\n #   }\n\n  if(type==\"ridge\" & gradFun != \"none\"){\n    warning(\"At this time, only gradFun=none recommended with ridge penalties\")\n  }\n\n # if(type==\"ridge\" & optMethod != \"nlminb\"){\n #   stop(\"For ridge, only use optMethod=nlminb and gradFun=none\")\n # }\n\n  if(type==\"lasso\"  & gradFun != \"ram\"){\n    warning(\"At this time, only gradFun=ram recommended with lasso penalties\")\n  }\n\n\n  if(type==\"diff_lasso\"  & gradFun != \"ram\"){\n    warning(\"At this time, only gradFun=ram recommended with lasso penalties\")\n  }\n #   parL = parTable(model)[,\"label\"]\n  #  if(sum(duplicated(parL[parL != \"\"])) > 0){\n #     stop(\"regsem currently does not allow equality constraints\")\n #   }\n\n\n  if(model@SampleStats@ngroups > 1){\n    stop(\"regsem currently does not work with multiple group models\")\n  }\n\n\n # lav.fits <- fitmeasures(model)\n\n#  if(model@Fit@converged == FALSE){\n#    sat.lik = NA\n#  }else{\n#    sat.lik <- as.numeric(lav.fits[\"unrestricted.logl\"])\n#  }\n\n\n\n\n    mats = extractMatrices(model)\n    nvar = model@pta$nvar[[1]][1]\n    nfac = model@pta$nfac[[1]][1]\n\n    if(missing==\"listwise\"){\n      calc_fit = \"cov\"\n      nobs = model@SampleStats@nobs[[1]][1]\n\n\n\n      # get mediation parameters\n      if(any(is.na(mats$mediation))==FALSE){\n        mediation_vals <- mats$mediation\n      }else{\n        mediation_vals <- NA\n      }\n\n      if(missing==\"listwise\"){\n        SampCov <- model@SampleStats@cov[][[1]]\n      }else{\n        SampCov <- model@implied$cov[[1]]\n      }\n\n\n      if(mats$mean == TRUE){\n        mm = mats$A[,\"1\"]\n\n        SampMean <- model@SampleStats@mean[][[1]]\n        ss = match(names(mm[mm > 0]),model@Data@ov$name)\n        SampMean[-c(ss)] = 0\n\n\n        SampCov2 <- SampCov + SampMean%*%t(SampMean)\n        # try changing size of SampCov\n        SampCov3 = cbind(SampCov2,SampMean)\n        SampCov = rbind(SampCov3,append(SampMean,1))\n      }else if(mats$mean == FALSE){\n       # SampCov <- model@SampleStats@cov[][[1]]\n        SampMean = NULL\n      }\n\n      #for grad ram with mean\n      SampCov22 <- model@SampleStats@cov[][[1]]# + SampMean %*% t(SampMean)\n\n    }else if(missing==\"fiml\"){\n      #stop(\"FIML is currently not supported at this time\")\n      calc_fit = \"ind\"\n      SampCov <- model@SampleStats@cov[][[1]]\n      mediation_vals <- NA\n\n      nobs = model@SampleStats@nobs[[1]][1]\n     # if(is.null(data)==TRUE){\n     #   stop(\"Dataset needs to be provided for missing==fiml\")\n     # }\n\n\n     # if(length(model@ParTable$op[model@ParTable$op == \"~1\"]) == 0){\n     #   stop(\"meanstructure needs to be equal to TRUE for FIML\")\n     # }\n\n    }\n    #SampCov <- fitted(model)$cov\n    #SampMean <- rep(0,nvar)\n\n    type2 = 0\n    if(type==\"lasso\"){\n      type2 = 1\n    }else if(type==\"ridge\"){\n      type2=2\n    }else if(type==\"diff_lasso\"){\n      type2=3\n    }else if(type==\"enet\"){\n      type2=4\n    }else if(type==\"alasso\"){ ## try just creating new pen_vec\n      type2=1\n    }else if(type==\"scad\"){\n      type2=6\n    }else if(type==\"mcp\"){\n      type2=7\n    }\n\n\n\n\n\n    #nUniq = nvar\n    #nFacCov\n    df = model@Fit@test[[1]]$df\n    npar = model@Fit@npar\n    nload = length(model@ParTable$op[model@ParTable$op == \"=~\"])\n\n\n\n\n  A <- mats$A\n  A_est <- mats$A_est\n  A_fixed <- mats$A_fixed\n  S <- mats$S\n  S_est <- mats$S_est\n  S_fixed <- mats$S_fixed\n  F <- mats$F\n  I <- diag(nrow(A))\n\n\n\n    if(is.null(pars_pen) == TRUE){\n      if(any(colnames(A) == \"1\")){\n        IntCol = which(colnames(A) == \"1\")\n        A_minusInt = A[,-IntCol]\n        A_pen = A_minusInt != 0\n        pars_pen = A_minusInt[A_pen]\n      }else{\n        A_pen = A != 0\n        pars_pen = A[A_pen]\n      }\n    }\n\n\n   if(class(Start)==\"numeric\"){\n      start=Start\n   }else if(class(Start) != \"numeric\"){\n     if(Start==\"lavaan\"){\n       # get starting values\n       start <- mats$parameters\n\n     } else if(Start == \"default\"){\n       nstart <- max(max(A),max(S))\n       start <- rep(0.5,nstart)\n\n     }\n   }\n\n\n\n\n\n  if(calc == \"normal\"){\n    calc = function(start){\n         mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n         #print(mult)\n\n         #mult2 = RAMmult(par=start,A,S,F,A_fixed,A_est,S_fixed,S_est)\n         #print(mult2)\n         pen_vec = c(mult$A_est22[match(pars_pen,A,nomatch=0)],mult$S_est22[match(pars_pen,S,nomatch=0)])\n         if(type==\"diff_lasso\"){\n           pen_diff = pen_vec - diff_par\n         }else{\n           pen_diff=0\n         }\n\n         #### for alasso - weight the parameters ####\n         #### overwrite pen_vec ########\n         if(type==\"alasso\"){\n           pen_vec_ml = c(list$A_est[match(pars_pen,A,nomatch=0)],list$S_est[match(pars_pen,S,nomatch=0)])\n           pen_vec = abs(pen_vec)*(1/(abs(pen_vec_ml)))\n         }\n\n         if(calc_fit==\"cov\"){\n           #fit = fit_fun(ImpCov=mult$ImpCov,SampCov,Areg=mult$A_est22,lambda,alpha,type,pen_vec)\n           fit = rcpp_fit_fun(ImpCov=mult$ImpCov,SampCov,type2,lambda,gamma,pen_vec,pen_diff,e_alpha)\n           #print(fit)\n          # print(type2)\n           #print(round(fit,3))#;print(pen_diff)\n           fit\n         }else if(calc_fit==\"ind\"){\n           stop(\"Not currently supported\")\n           #print(mult$ImpCov)\n\n           #fit = fiml_calc(ImpCov=mult$ImpCov,mu.hat=model@SampleStats@missing.h1[[1]]$mu,\n           #                h1=model@SampleStats@missing.h1[[1]]$h1,\n           #                Areg=mult$A_est22,lambda,alpha,type,pen_vec,nvar,\n           #                lav.miss=model@SampleStats@missing[[1]])\n          # fit = fiml_calc2(ImpCov=mult$ImpCov,F,mats2=mult,\n          #                 type=type,lambda=lambda,\n          #                 model=model,sat.lik=sat.lik,\n          #                 pen_vec=pen_vec)\n         }\n\n    }\n  }else if(calc == \"calc2\"){\n    calc = function(start){\n      #mult = RAMmult(par=start,A,S,F,A.fixed,A.est,S.fixed,S.est)\n      fit = ram_calc(par=start,SampCov22,A,S,F,SampMean)\n      like = fit$lik\n      like\n    }\n  }else if(calc == \"boot\"){\n    calc = function(start){\n      mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n      #mult = RAMmult(par=start,A,S,F,A_fixed,A_est,S_fixed,S_est)\n      pen_vec = c(mult$A_est22[match(pars_pen,A,nomatch=0)],mult$S_est22[match(pars_pen,S,nomatch=0)])\n      if(type==\"diff_lasso\"){\n        pen_diff = pen_vec - diff_par\n      }else{\n        pen_diff=0\n      }\n      n.boot=100\n      fits = rep(NA,n.boot)\n      # boot part\n      for(i in 1:n.boot){\n        dat1 = model@Data@X[[1]]\n        ids <- sample(nrow(dat1),nrow(dat1),replace=TRUE)\n        new.dat <- dat1[ids,]\n        SampCov.boot <- cov(new.dat)\n        #fits[i] = rcpp_fit_fun(ImpCov=mult$ImpCov,SampCov.boot,type2,lambda,pen_vec,pen_diff)\n        fits[i] = fit_fun(ImpCov=mult$ImpCov,SampCov.boot,lambda,alpha,type,pen_vec)\n      }\n      mean(fits)\n    }\n  }\n#------------------------ only works for CFA models --------------------------------\n#  grad = function(start){\n#    mult = RAM_multSimp(A,A.fixed,S,S.fixed,F,start,nfac,nvar)\n#    ret = gradient(ExpCov=mult$ExpCov,cov,A=mult$A,S=mult$S,\n#                   start,lambda,alpha,type,nvar,nload,nfac,nUniq,nFacCov)\n#    ret\n# }\n\n  if(gradFun==\"norm\"){\n    grad = function(start){\n\n      mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n                #mult = RAMmult(par=start,A,S,F,A_fixed,A_est,S_fixed,S_est)\n                ret = grad_fun(par=start,ImpCov=mult$ImpCov,SampCov,Areg = mult$A_est22,\n                               Sreg=mult$S_est22,A,A_fixed,A_est,S,S_fixed,S_est,\n                               F,lambda,alpha,type,pars_pen)\n               ret\n  }\n} else if(gradFun==\"ram\"){\n    grad = function(start){\n\n      mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n      #mult = RAMmult(par=start,A,S,F,A_fixed,A_est,S_fixed,S_est)\n\n      if(optMethod==\"coord_desc\"){\n        if(type2==1 | type2==3 | type2 ==4 | type2==6 | type2==7) type2=0\n\n\n        ret = rcpp_grad_ram(par=start,ImpCov=mult$ImpCov,SampCov,Areg = mult$A_est22,\n                            Sreg=mult$S_est22,A,S,\n                            F,lambda,type2=type2,pars_pen,diff_par=0)\n      }else{\n\n           ret = rcpp_grad_ram(par=start,ImpCov=mult$ImpCov,SampCov,Areg = mult$A_est22,\n                           Sreg=mult$S_est22,A,S,\n                             F,lambda,type2=type2,pars_pen,diff_par=0)\n        }\n\n\n      ret\n    }\n\n}else if(gradFun==\"ram_mean\"){\n  grad = function(start){\n\n    mult = ram_calc(par=start,SampCov22,A,S,F,SampMean)\n    ret = grad_ram_wMean(par=start,ImpCov=mult$ImpCov,SampCov22,Areg = mult$A2,\n                    Sreg=mult$S2,A=mult$A.pars,S=mult$S.pars,\n                    F=mult$F,SampMean,lambda,type,m=mult$m,mu=mult$mu,m.pars=mult$m.pars)\n    ret\n  }\n} else if(gradFun==\"numDeriv\"){\n    grad = function(start){\n\n    #mult = RAMmult(par=start,A,S,F,A.fixed,A.est,S.fixed,S.est)\n    ret = numDeriv::grad(calc,x=start)\n    ret\n  }\n} else if(gradFun==\"auto\"){\n  grad = function(start){\nstop(\"gradFun = auto is not supported at this time\")\n\n  #  ret = numderiv(calc,x=start)\n  #  ret\n  }\n}\n\n\n  if(hessFun==\"norm\"){\n\n    if(parallel==\"no\"){\n\n    hess = function(start){\n\n        mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n        #mult = RAMmult(par=start,A,S,F,A_fixed,A_est,S_fixed,S_est)\n        retH = hessian(par=start,ImpCov=mult$ImpCov,SampCov,A,A_fixed,A_est,\n                 S,S_fixed,S_est,F)\n        retH\n    }\n  } else if(parallel==\"yes\"){\n    stop(\"not supported\")\n  #  hess = function(start){\n  #  mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n    #mult = RAMmult(par=start,A,S,F,A.fixed,A.est,S.fixed,S.est)\n  #  retH = hessian_parallel(par=start,ImpCov=mult$ImpCov,A,A.fixed,A.est,\n  #                 S,S.fixed,S.est,F)\n   # retH\n#  }\n}\n}  else if(hessFun==\"ram\"){\n\n    if(parallel==\"no\"){\n    hess = function(start){\n\n      mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n      #mult = RAMmult(par=start,A,S,F,A_fixed,A_est,S_fixed,S_est)\n      ret = hess_ram(par=start,ImpCov=mult$ImpCov,SampCov,Areg = mult$A_est22,\n                      Sreg=mult$S_est22,A,S,F)\n      ret\n    }\n  } else if(parallel==\"yes\"){\n      hess = function(start){\n        mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n        #mult = RAMmult(par=start,A,S,F,A.fixed,A.est,S.fixed,S.est)\n        ret = hess_ramParallel(par=start,ImpCov=mult$ImpCov,SampCov,Areg = mult$A.est22,\n                        Sreg=mult$S.est22,A,S,F)\n        ret\n      }\n\n    }\n} else if(hessFun==\"numDeriv\"){\n  hess = function(start){\n\n    #mult = RAMmult(par=start,A,S,F,A.fixed,A.est,S.fixed,S.est)\n    ret = numDeriv::hessian(calc,x=start)\n    ret\n  }\n}else{\n  hess = NULL\n}\n\n    res <- list()\n\nif(optMethod==\"nlminb\"){\n    if(gradFun==\"norm\"){\n      if(hessFun==\"norm\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(abs(diag(S)-max(A)),rep(-10,max(S)-max(diag(S))))\n        #UB = c(100,100,100,1)\n        out <- nlminb(start,calc,grad,hess,lower=LB,upper=UB,control=list(eval.max=max.iter,\n                                                                 iter.max=max.iter))\n        res$out <- out\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }else if(hessFun==\"none\"){\n       #LB = c(rep(-6,max(A)),rep(1e-6,rep(-10,max(S)-max(diag(S))),max(diag(S))-max(A)))\n        out <- nlminb(start,calc,grad,lower=LB,upper=UB,control=list(eval.max=max.iter,\n                                                                     iter.max=max.iter))\n        res$out <- out\n\n        res$convergence = out$convergence\n        #res$optim_fit <- out$objective\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }\n    }else if(gradFun==\"ram\"){\n      if(hessFun==\"ram\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n       out <- nlminb(start,calc,grad,hess,lower=LB,upper=UB,control=nlminb.control)\n        res$out <- out\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }else if(hessFun==\"norm\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- nlminb(start,calc,grad,hess,lower=LB,upper=UB,control=nlminb.control)\n        res$out <- out\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        res$iteration = out$iterations\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }else if(hessFun==\"none\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n       suppressWarnings(out <- nlminb(start,calc,grad,lower=LB,upper=UB,\n                     control=nlminb.control)) #,x.tol=1.5e-6\n        res$out <- out\n        res$iteration = out$iterations\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }\n    }else if(gradFun==\"none\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- nlminb(start,calc,lower=LB,upper=UB,control=nlminb.control)\n        res$out <- out\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n    }else if(gradFun==\"ram_mean\"){\n      if(hessFun==\"ram\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- nlminb(start,calc,grad,hess,lower=LB,control=list(eval.max=max.iter,\n                                                                 iter.max=max.iter))\n        res$out <- out\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }else if(hessFun==\"none\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- nlminb(start,calc2,grad,lower=LB,upper=UB,eval.max=max.iter,\n                      iter.max=max.iter)\n        res$out <- out\n        res$convergence = out$convergence\n        #res$optim_fit <- out$objective\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }\n    }else if(gradFun==\"none\"){\n      #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n      out <- nlminb(start,calc,lower=LB,upper=UB,control=nlminb.control)\n      res$out <- out\n      #res$optim_fit <- out$objective\n      res$convergence = out$convergence\n      par.ret <- out$par\n      #res$iterations <- out$iterations\n    }else if(gradFun==\"numDeriv\"){\n      if(hessFun==\"numDeriv\"){\n        warning(\"numDeriv does not seem to be accurate at this time\")\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- nlminb(start,calc,grad,hess,lower=LB,upper=UB,control=nlminb.control)\n        res$out <- out\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }else if(hessFun==\"none\"){\n        warning(\"numDeriv does not seem to be accurate at this time\")\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- nlminb(start,calc,lower=LB,upper=UB,gradient=grad,control=nlminb.control)\n        res$out <- out\n        #res$optim_fit <- out$objective\n        res$convergence = out$convergence\n        par.ret <- out$par\n        #res$iterations <- out$iterations\n      }\n    }\n}else if(optMethod==\"optimx\"){\n    if(gradFun==\"norm\"){\n      if(hessFun==\"norm\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- optimx::optimx(start,calc,grad,hess,method=subOpt,lower=LB,upper=UB,control=list(starttests=FALSE))\n        res$out <- out\n        #res$iterations <- out$fevals\n\n        res$convergence = out$convcode\n        par.ret <- coef(out)\n      }else if(hessFun==\"none\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- optimx::optimx(start,calc,grad,lower=LB,upper=UB,method=subOpt,control=list(starttests=FALSE))\n        res$out <- out\n        #res$iterations <- out$fevals\n        res$convergence = out$convcode\n        par.ret <- coef(out)\n      }\n    }else if(gradFun==\"ram_mean\"){\n      if(hessFun==\"ram\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- optimx::optimx(start,calc,grad,hess,lower=LB,upper=UB,method=subOpt,control=list(starttests=FALSE))\n        res$out <- out\n        #res$iterations <- out$fevals\n        res$convergence = out$convcode\n        par.ret <- coef(out)\n      }else if(hessFun==\"none\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- optimx::optimx(start,calc,grad,method=subOpt,lower=LB,upper=UB,control=list(starttests=FALSE))\n        res$out <- out\n        res$convergence = out$convcode\n        par.ret <- coef(out)\n       }\n    }else if(gradFun==\"ram\"){\n      if(hessFun==\"ram\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- optimx::optimx(start,calc,grad,hess,method=subOpt,lower=LB,upper=UB,control=list(starttests=FALSE,itnmax = max.iter))\n        res$out <- out\n        #res$optim_fit <- out$value\n        res$convergence = out$convcode\n        par.ret <- coef(out)\n      }else if(hessFun==\"none\"){\n        #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-max(A)),rep(-10,max(S)-max(diag(S))))\n        out <- optimx::optimx(start,calc,grad,method=subOpt,lower=LB,upper=UB,control=list(starttests=FALSE))\n        res$out <- out\n        #res$iterations <- out$fevals\n        #res$optim_fit <- out$value\n        res$convergence = out$convcode\n        par.ret <- coef(out)\n      }\n    }else if(gradFun==\"none\"){\n      #LB = c(rep(-6,max(A)),rep(1e-6,max(diag(S))-S[1,1]+1),rep(-10,max(S)-max(diag(S))))\n      out <- optimx::optimx(start,calc,method=subOpt,itnmax=1500,lower=LB,upper=UB,\n                    hessian=T,control=list(maxit=1500,starttests=FALSE,all.methods=TRUE,abstol=1e-12))\n      res$out <- out\n      #res$iterations <- out$fevals\n      res$convergence = out$convcode\n      #pars <- coef(out)\n      #res$pars <- pars\n      par.ret <- coef(out)\n    }\n}else if(optMethod==\"rsolnp\"){\n       # if(UB == Inf) UB=NULL\n       # if(LB == -Inf) LB=NULL\n        suppressWarnings(out <- Rsolnp::solnp(start,calc,LB=LB,UB=UB,\n                                              control=list(trace=0,tol=1e-16)))#tol=1e-16\n        #out <- optim(par=start,fn=calc,gr=grad)\n        res$out <- out\n        #res$iterations <- out$nfunevals\n        res$convergence = out$convergence\n        par.ret <- out$pars\n\n}else if(optMethod==\"rgenoud\"){\n  dom = matrix(c(LB,UB),nrow=length(start),2)\n  suppressWarnings(out <- rgenoud::genoud(calc,starting.values=start,Domains=dom,\n                                      nvars=length(start),print.level=0,gr=grad,\n                                      boundary.enforcement=2,\n                                      wait.generations=3))\n  res$out <- out\n  res$optim_fit <- out$value\n  res$convergence = 0\n  res$par.ret <- out$par\n}else if(optMethod==\"GA\"){\n  calc2 = function(start){\n    10-calc(start)\n  }\n  out = GA::ga(\"real-valued\", fitness = calc2, nBits = length(start),\n               min=LB,max=UB,monitor=FALSE,pcrossover=0.9,pmutation=0.3,\n               maxiter=10000)\n  res$out <- summary(out)\n  res$optim_fit <- 10 - summary(out)$fitness\n  res$convergence = 0\n  res$par.ret <- summary(out)$solution\n}else if(optMethod==\"coord_desc\"){\n\n\n  if(type==\"alasso\"){\n    mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n    pen_vec = c(mult$A_est22[match(pars_pen,A,nomatch=0)],mult$S_est22[match(pars_pen,S,nomatch=0)])\n    pen_vec_ml = c(list$A_est[match(pars_pen,A,nomatch=0)],list$S_est[match(pars_pen,S,nomatch=0)])\n    pen_vec = abs(pen_vec)*(1/(abs(pen_vec_ml)))\n  }\n\n\n\n  out = coord_desc(start=start,func=calc,type=type,grad=grad,\n                   hess=hess,hessFun=hessFun,\n                   pars_pen=pars_pen,model=model,max.iter=max.iter,\n                   lambda=lambda,mats=mats,block=block,tol=tol,full=full,\n                   solver=solver,solver.maxit=solver.maxit,\n                   alpha.inc=alpha.inc,step=step,momentum=momentum,\n                   e_alpha=e_alpha,gamma=gamma,\n                   par.lim=par.lim,\n                   step.ratio=step.ratio,diff_par=diff_par,pen_vec=pen_vec)\n  res$out <- out\n  res$optim_fit <- out$value\n  #print(out$convergence)\n\n    res$convergence <- out$convergence\n\n  par.ret <- out$pars\n  res$iterations <- out$iterations\n}\n\n\n\n   # imp_cov = RAMmult(res$out$par,A,S,F,A.fixed,A.est,S.fixed,S.est) [[1]]\n   # res$imp_cov <- imp_cov\n    #res$df <- df\n    #res$nobs <- nobs\n    #res$nload <- nload\n\n    #hess <- ret_hess(res$out$par,A,S,F,A_fixed,A_est,S_fixed,S_est)\n    #res$hess <- hess\n    #res$info <- ginv((nobs/2)*hess)\n    #res$A <- A\n    #res$S <- S\n    #res$A.est <- A_est\n    #res$A.fixed <- A_fixed\n    #res$S_est <- S_est\n    #res$S.fixed <- S_fixed\n   # res$F <- F\n\n\n    pars.df <- data.frame(matrix(NA,1,max(max(A),max(S))))\n    pars.df[1,] <- par.ret\n\n#    if(any(pars.df[diag(S[diag(S) != 0])] < 0)){\n#      warning(\"Some Variances are Negative!\")\n#      res$convergence <- 2\n #   }\n\n\n\n\n\n    if(type==\"ridge\"){\n      hess = function(start){\n\n        mult = rcpp_RAMmult(par=start,A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n        #mult = RAMmult(par=start,A,S,F,A_fixed,A_est,S_fixed,S_est)\n        ret = hess_ram(par=start,ImpCov=mult$ImpCov,SampCov,Areg = mult$A_est22,\n                       Sreg=mult$S_est22,A,S,F)\n        ret\n      }\n      hess.mat = hess(as.numeric(pars.df))\n      res$hess <- hess.mat\n    }\n\n\n    #res$ftt = rcpp_RAMmult(par=as.numeric(pars.df),A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n      # get Implied Covariance matrix\n\n    mult.out <- rcpp_RAMmult(par=as.numeric(pars.df),A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n    Imp_Cov1 <- mult.out$ImpCov\n    #Imp_Cov <- RAMmult(par=as.numeric(pars.df),A,S,F,A_fixed,A_est,S_fixed,S_est)$ImpCov\n\n    pen_vec = c(mult.out$A_est22[match(pars_pen,A,nomatch=0)],mult.out$S_est22[match(pars_pen,S,nomatch=0)])\n\n    if(mats$mean==TRUE & missing==\"listwise\"){\n      Imp_Cov = Imp_Cov1[1:(nrow(Imp_Cov1)-1),1:(ncol(Imp_Cov1)-1)] - SampMean %*% t(SampMean)\n    }else{\n      Imp_Cov = Imp_Cov1\n    }\n\n    res$Imp_Cov <- Imp_Cov\n\n    res$Imp_Cov1 <- Imp_Cov1\n\n     # N = nobs; p=nvar; SampCov00 <- model@SampleStats@cov[][[1]]\n     # c <- N*p/2 * log(2 * pi)\n      #res$logl_sat <- -c -(N/2) * log(det(SampCov00)) - (N/2)*p\n\n#    if(model@Fit@converged == FALSE){\n#      res$logl_sat= NA\n#    }else{\n #     res$logl_sat <- as.numeric(lav.fits[\"unrestricted.logl\"])\n #   }\n\n\n    #res$grad <- grad(as.numeric(pars.df))\n    #### KKT conditions #####\n    if(gradFun==\"none\"){\n      res$KKT1 = \"grad not specified\"\n    }else{\n      res$grad <- grad(as.numeric(pars.df))\n      kk = try(all(grad(as.numeric(pars.df)) < 0.001))\n      if(inherits(kk, \"try-error\")){\n        res$KKT1 = \"error\"\n      }else{\n        if(kk == TRUE){\n          res$KKT1 = TRUE\n        }else if(kk < 0.001){\n          res$KKT1 = FALSE\n        }else{\n          res$KKT1 = NA\n        }\n      }\n    }\n\n\n    if(hessFun==\"none\"){\n      res$KKT2 = \"hess not specified\"\n    }else{\n      hess.mat = hess(as.numeric(pars.df))\n      eig = eigen(hess.mat)$values\n      hess.eigs = try(all(eig) > 1e-6)\n      if(inherits(hess.eigs, \"try-error\")){\n        res$KKT2 = \"error\"\n      }else{\n        if(hess.eigs == TRUE){\n          res$KKT2 = TRUE\n        }else if(hess.eigs == FALSE){\n          res$KKT2 = FALSE\n        }else{\n          res$KKT2 = NA\n        }\n      }\n    }\n\n\n\n\n   # rettt = rcpp_RAMmult(par=as.numeric(pars.df),A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n   # A_new2 <- rettt$A_est22\n   # S_new2 <- rettt$S_est22\n    #A_new <- A\n    #S_new <- S\n    #I = diag(ncol(A))\n\n    #for(i in 1:max(A)) A_new[A_new==i] = pars.df[i]\n    #A_new2 = matrix(unlist(A_new),nrow(A),ncol(A))\n\n    #for(i in min(S[S>0]):max(S)) S_new[S_new==i] = pars.df[i]\n    #S_new2 = matrix(unlist(S_new),nrow(S),ncol(S))\n    #res$retttt = calc(as.numeric(pars.df))\n    #res$Imp_Cov = F %*% solve(I-A_new2) %*% S_new2 %*% t(solve(I-A_new2)) %*% t(F)\n    #res$fitt =  calc(as.numeric(pars.df))\n\n    for(i in 1:ncol(pars.df)){\n      if(any(A == i)){\n        pos = which(A == i,arr.ind=T)\n        one = colnames(A)[pos[2]]\n        two = rownames(A)[pos[1]]\n        names(pars.df)[i] = paste(one,\"->\",two)\n      }else if(any(S==i)){\n        pos = which(S == i,arr.ind=T)\n        one = colnames(S)[pos[2]]\n        two = rownames(S)[pos[1]]\n        names(pars.df)[i] = paste(one,\"~~\",two)\n      }\n    }\n\n\n    if(type==\"none\" | lambda==0){\n      res$df = df\n      res$npar = npar\n    }else if(type==\"lasso\" | type==\"alasso\" | type==\"enet\" | type==\"scad\" | type==\"mcp\"){\n      #A_estim = A != 0\n      #pars = A_est[A_estim]\n      pars_sum = pars.df[pars_pen]\n      pars_l2 = sqrt(pars_sum**2)\n      res$df = df + sum(pars_l2 < 0.001)\n      res$npar = npar - sum(pars_l2 < 0.001)\n\n    }else if(type==\"ridge\"){\n      #ratio1 <- sqrt(pars.df[pars_pen]**2)/sqrt(mats$parameters[pars_pen]**2)\n      res$df = df #+ length(ratio1) - sum(ratio1)\n      res$npar = npar #- sum(ratio1)\n    }else if(type==\"diff_lasso\"){\n      pars_sum = as.numeric(pars.df[pars_pen])\n      #print(pars_sum);print(duplicated(round(pars_sum,3)))\n      res$df = df + sum(duplicated(round(pars_sum,3)))\n      res$npar = npar - sum(duplicated(round(pars_sum,3)))\n\n    }\n\n\n      if(optMethod==\"nlminb\"){\n        optFit <- out$objective\n      }else{\n        optFit <- res$optim_fit\n      }\n\n\n    if(missing == \"listwise\"){\n     # SampCov <- model@SampleStats@cov[][[1]]\n    #  res$SampCov = SampCov\n      #res$fit = 0.5*(log(det(Imp_Cov1)) + trace(SampCov %*% solve(Imp_Cov1)) -\n       #              log(det(SampCov))  - nvar)\n     # pen_vec = c(mult$A_est22[A %in% pars_pen],mult$S_est22[S %in% pars_pen])\n      if(type==\"diff_lasso\"){\n        pen_diff = pen_vec - diff_par\n      }else{\n        pen_diff=0\n      }\n      res$fit = rcpp_fit_fun(Imp_Cov1, SampCov,type2=0,lambda=0,pen_vec=0,pen_diff=pen_diff,e_alpha=0,gamma=0)\n    }else if(missing == \"fiml\" & type == \"none\"){\n      #print(res$optim_fit)\n      res$fit = (optFit/nobs)*.5\n     # res$fit = rcpp_fit_fun(ImpCov=Imp_Cov,SampCov,\n     #                        type2,lambda,pen_vec=0,pen_diff=0)\n      #SampCov <- model@implied$cov[[i]]\n      #res$fit = rcpp_fit_fun(Imp_Cov1, SampCov,type2=0,lambda=0,pen_vec=0,pen_diff=0)\n    }else if(missing==\"fiml\" & type != \"none\"){\n      res$fit = rcpp_fit_fun(ImpCov=Imp_Cov,SampCov,\n                             type2,lambda,pen_vec=0,pen_diff=0,e_alpha=0,gamma=0)\n\n    }\n\n    SampCov <- model@SampleStats@cov[][[1]]\n    res$SampCov = SampCov\n\n    res$data <- as.data.frame(model@Data@X)\n\n    res$coefficients <- round(pars.df,3)\n    res$nvar = nvar\n    res$N = nobs\n    res$nfac = nfac\n\n#    if(model@Fit@converged == FALSE){\n#      res$baseline.chisq = NA\n#      res$baseline.df = NA\n#    }else{\n#      res$baseline.chisq = lav.fits[\"baseline.chisq\"]\n#      res$baseline.df = lav.fits[\"baseline.df\"]\n#    }\n\n    #res$grad <- grad(res$par.ret)\n\n   # res$hess <- hess(as.numeric(res$par.ret))\n    if(any(is.na(mediation_vals))==FALSE){\n\n      rettt = rcpp_RAMmult(par=as.numeric(pars.df),A,S,S_fixed,A_fixed,A_est,S_est,F,I)\n       A_est <- rettt$A_est22\n       S_est <- rettt$S_est22\n       #A_new <- A\n\n       #S_new <- S\n\n     ppars <- mediation_vals$pars.mult\n\n     #mediation_vals\n\n\n\n    parT <- lavaan::parTable(model)\n\n    par.labels <- parT$free > 0 & parT$label != \"\"\n    val <- rep(NA,nrow(parT[par.labels,]))\n\n    for(i in 1:nrow(parT[par.labels,])){\n      par <- parT$label[i]\n      par.num <- parT$free[i]\n\n\n        if(any(A==par.num)){\n        val[i] <- round(A_est[A==par.num],3)\n        }else if(any(S==par.num)){\n        val[i] <- round(S_est[S==par.num],3)\n        }\n    }\n\n    labs <- parT$label[par.labels]\n\n    for(i in length(labs):1){\n      for(j in 1:length(ppars)){\n        ppars[j] <- gsub(labs[i],val[i],ppars[j])\n      }\n    }\n\n   return.vals <- rep(NA,length(ppars))\n   for(i in 1:length(ppars)){\n     return.vals[i] <- eval(parse(text=ppars[i]))\n   }\n\n\n   ppars <- mediation_vals$pars.mult\n\n   for(i in 1:length(ppars)){\n     first <- paste(\"=\",return.vals[i])\n     ppars[i] <- paste(ppars[i],first)\n   }\n\n   res$mediation <- ppars\n   res$mediation_vals <- return.vals\n\n\n    }\n\n\n    if(lambda > 0){\n      res$pars_pen <- pars_pen\n    }else{\n      res$pars_pen <- NULL\n    }\n\n    res$mean <- mats$mean\n\n    res$lav.model <- model\n\n    if(res$convergence != 0){\n      warning(\"WARNING: Model did not converge! It is recommended to try multi_optim() or\n              change step.ratio=TRUE\")\n    }\n\n    res$call <- match.call()\n    class(res) <- \"regsem\"\n    return(res)\n}\n",
    "created" : 1488225908756.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "279305133",
    "id" : "E1A68BDB",
    "lastKnownWriteTime" : 1484160082,
    "last_content_update" : 1484160082,
    "path" : "~/GitHub/regsem/R/regsem.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 9,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}