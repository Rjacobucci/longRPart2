{
    "collab_server" : "",
    "contents" : "wisc <- read.table(\"C:/Users/RJacobucci/Documents/GitHub/EDM_Labs/2015/wisc4vpe.dat\")\nnames(wisc)<- c(\"V1\",\"V2\",\"V4\",\"V6\",\"P1\",\"P2\",\"P4\", \"P6\", \"Moeducat\")\n\n\n\n\nwisc.verb <- wisc[,c(1:4,9)]\n\n# create subset for plotting\nntot <- nrow(wisc.verb)    # total number of observations\nwisc.verb.sel <- wisc.verb[sample(ntot, 30), ]\n\nwisc.long <- reshape(wisc.verb, varying = c(\"V1\", \"V2\", \"V4\", \"V6\"), v.names = \"verbal\",\n                     times = c(1, 2, 4, 6), direction = \"long\")\n\nwisc.long.sel <- reshape(wisc.verb.sel, varying = c(\"V1\", \"V2\", \"V4\", \"V6\"),\n                         v.names = \"verbal\", times = c(1, 2, 4, 6),\n                         direction = \"long\")\nhead(wisc.long,3)\nnames(wisc.long)[2] <- \"grade\"\nnames(wisc.long.sel)[2] <- \"grade\"\n\n\n\n\n\n\nmix1 <- lme(fixed = verbal ~ grade, random = ~ grade | id,\n            data = wisc.long, method=\"ML\" )\nsummary(mix1) # get same estimates as in LGM, notice SD not VAR\n\n## longRPart2\n\n\nlcart.mod1 <- longRPart2(method=\"lme\",\n                         fixedFormula=verbal ~ grade,\n                         rPartFormula = ~ Moeducat,\n                         randomFormula=~1|id,\n                         data=wisc.long)\n\nsummary(lcart.mod1)\n\n\n\nlrpPlot(lcart.mod1)\nlrpTreePlot(lcart.mod1,use.n=F)\n",
    "created" : 1481566574034.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1830247496",
    "id" : "9FFB5D3D",
    "lastKnownWriteTime" : 1481569822,
    "last_content_update" : 1481569822913,
    "path" : "~/GitHub/longRPart2/test.R",
    "project_path" : "test.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}